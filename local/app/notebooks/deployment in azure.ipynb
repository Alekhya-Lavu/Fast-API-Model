{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy ONNX model as a WebService in the Azure Cloud<br>\n",
    "<br>\n",
    "There are four steps which are needed to follow when you deploy your model.<br>\n",
    "1. Register the model.<br>\n",
    "2. Prepare to deploy. (Specify assets, usage, compute target).<br>\n",
    "3. Deploy the model to the compute target.<br>\n",
    "4. Test the deployed model, also called a web service.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Initialize Azure Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note, we have launched a browser for you to login. For old experience with device code, use \"az login --use-device-code\"\n",
      "You have logged in. Now let us find all the subscriptions to which you have access...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive authentication successfully completed.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config(r'C:\\Users\\ASUS\\Desktop\\app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Register your ONNX model with Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model house.onnx\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "# Tip: When model_path is set to a directory, you can use the child_paths parameter to include\n",
    "#      only some of the files from the directory\n",
    "model = Model.register(model_path = \"C:/Users/ASUS/Desktop/app/models\",\n",
    "                       model_name = \"house.onnx\",\n",
    "                       description = \"Boston house model trained outside Azure Machine Learning\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare to Deploy\n",
    "###### 1. Define inference configuration Environment file<br>\n",
    "Defining dependencies that are required to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create the environment\n",
    "myenv = Environment(name=\"myenv\")\n",
    "conda_dep = CondaDependencies()\n",
    "\n",
    "# Define the packages needed by the model and scripts\n",
    "conda_dep.add_pip_package(\"pydantic\")\n",
    "conda_dep.add_pip_package(\"numpy\")\n",
    "conda_dep.add_pip_package(\"scikit-learn\")\n",
    "conda_dep.add_pip_package(\"skl2onnx\")\n",
    "conda_dep.add_pip_package(\"onnxruntime\")\n",
    "conda_dep.add_pip_package(\"sklearn\")\n",
    "\n",
    "# You must list azureml-defaults as a pip dependency\n",
    "conda_dep.add_pip_package(\"azureml-defaults\")\n",
    "\n",
    "# Adds dependencies to PythonSection of myenv\n",
    "myenv.python.conda_dependencies=conda_dep\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Define scoring code<br>\n",
    "An entry script. This file (named score.py) loads the model when the deployed service starts. It is also responsible for receiving data, passing it to the model, and then returning a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script=\"C:/Users/ASUS/Desktop/app/score.py\",environment=myenv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Define inference configuration<br>\n",
    "Defining the deployment target class.Here i used Azure Container Instance servive class as webservice.Used for low-scale CPU-based workloads that require less than 48 GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..............................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "scoring URI:  http://5f00c0fd-1012-4d32-b6da-dbeb4b2c5d39.centralus.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"aciservice\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(\"scoring URI: \",service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service.get_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Access the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(\n",
    "    service.scoring_uri, json = [0.06263,0.0,11.93,0.0,0.573,6.593,69.1,2.4786,1.0,273.0,21.0,391.99,9.67], headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction': 23.21451187133789}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Conclusion<br>\n",
    "Therefore, we deployed our model as a web service and consumed the response back as a price provided the request with the features of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### References\n",
    "<br>https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-existing-model<br>\n",
    "https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where<br>\n",
    "https://towardsdatascience.com/deploy-your-machine-learning-model-as-a-rest-api-4fe96bf8ddcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
